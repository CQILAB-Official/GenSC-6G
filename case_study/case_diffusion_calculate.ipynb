{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_communication.diffusion_super_res import DiffusionSuperRes, DiffusionUpscaler\n",
    "import torch\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "images_folder_input = \"logs/upsampling/log-vit/snr_30/output\"\n",
    "images_folder_output = \"logs/upsampling/log-vit/snr_30/diffusion\"\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "diffusion_super_res = DiffusionSuperRes(device)\n",
    "# diffusion_upscaler = DiffusionUpscaler(device)\n",
    "\n",
    "for filename in os.listdir(images_folder_input):\n",
    "    if filename.endswith(\".png\") or filename.endswith(\".jpg\"):\n",
    "        img_path = os.path.join(images_folder_input, filename)\n",
    "\n",
    "        # Open the image using PIL\n",
    "        img_pil = Image.open(img_path).convert('RGB')\n",
    "\n",
    "        # Run the diffusion model (using 200 as the inference step count)\n",
    "        output_img = diffusion_super_res.inference(img_pil, 200)\n",
    "\n",
    "        # Save the output image in the output folder with the same filename\n",
    "        output_path = os.path.join(images_folder_output, filename)\n",
    "        output_img.save(output_path)\n",
    "\n",
    "        print(f\"Processed and saved: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cqilab/anaconda3/envs/sgrs/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/cqilab/anaconda3/envs/sgrs/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: /home/cqilab/anaconda3/envs/sgrs/lib/python3.11/site-packages/lpips/weights/v0.1/alex.pth\n",
      "SNR 1: Average LPIPS = 18.840259552001953\n",
      "SNR 2: Average LPIPS = 20.96728515625\n",
      "SNR 3: Average LPIPS = 21.931808471679688\n",
      "SNR 4: Average LPIPS = 22.478090286254883\n",
      "SNR 5: Average LPIPS = 22.8260498046875\n",
      "SNR 6: Average LPIPS = 23.048362731933594\n",
      "SNR 7: Average LPIPS = 23.196651458740234\n",
      "SNR 8: Average LPIPS = 23.307106018066406\n",
      "SNR 9: Average LPIPS = 23.394601821899414\n",
      "SNR 10: Average LPIPS = 23.441608428955078\n",
      "SNR 11: Average LPIPS = 23.509063720703125\n",
      "SNR 12: Average LPIPS = 23.58000373840332\n",
      "SNR 13: Average LPIPS = 23.583158493041992\n",
      "SNR 14: Average LPIPS = 23.608240127563477\n",
      "SNR 15: Average LPIPS = 23.64699363708496\n",
      "SNR 16: Average LPIPS = 23.651119232177734\n",
      "SNR 17: Average LPIPS = 23.66393280029297\n",
      "SNR 18: Average LPIPS = 23.687097549438477\n",
      "SNR 19: Average LPIPS = 23.68998908996582\n",
      "SNR 20: Average LPIPS = 23.744665145874023\n",
      "SNR 21: Average LPIPS = 23.724538803100586\n",
      "SNR 22: Average LPIPS = 23.743080139160156\n",
      "SNR 23: Average LPIPS = 23.747068405151367\n",
      "SNR 24: Average LPIPS = 23.74747657775879\n",
      "SNR 25: Average LPIPS = 23.77068328857422\n",
      "SNR 26: Average LPIPS = 23.779861450195312\n",
      "SNR 27: Average LPIPS = 23.75554656982422\n",
      "SNR 28: Average LPIPS = 23.784629821777344\n",
      "SNR 29: Average LPIPS = 23.796871185302734\n",
      "SNR 30: Average LPIPS = 23.79546546936035\n",
      "SNR 1: Average LPIPS = 18.8403\n",
      "SNR 2: Average LPIPS = 20.9673\n",
      "SNR 3: Average LPIPS = 21.9318\n",
      "SNR 4: Average LPIPS = 22.4781\n",
      "SNR 5: Average LPIPS = 22.8260\n",
      "SNR 6: Average LPIPS = 23.0484\n",
      "SNR 7: Average LPIPS = 23.1967\n",
      "SNR 8: Average LPIPS = 23.3071\n",
      "SNR 9: Average LPIPS = 23.3946\n",
      "SNR 10: Average LPIPS = 23.4416\n",
      "SNR 11: Average LPIPS = 23.5091\n",
      "SNR 12: Average LPIPS = 23.5800\n",
      "SNR 13: Average LPIPS = 23.5832\n",
      "SNR 14: Average LPIPS = 23.6082\n",
      "SNR 15: Average LPIPS = 23.6470\n",
      "SNR 16: Average LPIPS = 23.6511\n",
      "SNR 17: Average LPIPS = 23.6639\n",
      "SNR 18: Average LPIPS = 23.6871\n",
      "SNR 19: Average LPIPS = 23.6900\n",
      "SNR 20: Average LPIPS = 23.7447\n",
      "SNR 21: Average LPIPS = 23.7245\n",
      "SNR 22: Average LPIPS = 23.7431\n",
      "SNR 23: Average LPIPS = 23.7471\n",
      "SNR 24: Average LPIPS = 23.7475\n",
      "SNR 25: Average LPIPS = 23.7707\n",
      "SNR 26: Average LPIPS = 23.7799\n",
      "SNR 27: Average LPIPS = 23.7555\n",
      "SNR 28: Average LPIPS = 23.7846\n",
      "SNR 29: Average LPIPS = 23.7969\n",
      "SNR 30: Average LPIPS = 23.7955\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from semantic_communication.metrics import calculate_lpips_similarity, calculate_psnr_np, calculate_psnr\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Loop over SNR values from 1 to 30\n",
    "snr_values = range(1, 31)\n",
    "results = []\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((112, 112)),  # Resize the image to 112x112\n",
    "    transforms.ToTensor(),          # Convert the image to a tensor\n",
    "    # transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize the tensor\n",
    "])\n",
    "\n",
    "for snr in snr_values:\n",
    "    # Update the folder paths for the current SNR\n",
    "    input_folder = f\"logs/upsampling/log-vit/snr_{snr}/input\"\n",
    "    output_folder = f\"logs/upsampling/log-vit/snr_{snr}/diffusion\"\n",
    "    \n",
    "    # Ensure both folders exist\n",
    "    if not os.path.exists(input_folder) or not os.path.exists(output_folder):\n",
    "        print(f\"Skipping SNR {snr} because the input or output folder does not exist.\")\n",
    "        continue\n",
    "\n",
    "    # Initialize list to store LPIPS values\n",
    "    lpips_values = []\n",
    "\n",
    "    # Iterate through all images in the input folder\n",
    "    for filename in os.listdir(input_folder):\n",
    "        # Construct the input and output file paths\n",
    "        index = filename.split('_')[1]  # Get the index from input_{index}.png\n",
    "        input_image_path = os.path.join(input_folder, f\"input_{index}\")\n",
    "        output_image_path = os.path.join(output_folder, f\"output_{index}\")\n",
    "\n",
    "        input_img = Image.open(input_image_path).convert('RGB')\n",
    "        output_img = Image.open(output_image_path).convert('RGB')\n",
    "        \n",
    "        # Convert to tensor\n",
    "        input_img_tensor = transform(input_img).unsqueeze(0)  # Add batch dimension\n",
    "        output_img_tensor = transform(output_img).unsqueeze(0)\n",
    "\n",
    "        # Calculate LPIPS\n",
    "        lpips_value = calculate_psnr(input_img_tensor, output_img_tensor)\n",
    "\n",
    "        # Append the value to the list\n",
    "        lpips_values.append(lpips_value)\n",
    "\n",
    "    # Calculate the average LPIPS for this SNR\n",
    "    if lpips_values:\n",
    "        avg_lpips = np.mean(lpips_values)\n",
    "        results.append({'snr': snr, 'avg_lpips': avg_lpips})\n",
    "        print(f\"SNR {snr}: Average LPIPS = {avg_lpips}\")\n",
    "    else:\n",
    "        print(f\"No valid comparisons found for SNR {snr}.\")\n",
    "\n",
    "# Output the results\n",
    "for result in results:\n",
    "    print(f\"SNR {result['snr']}: Average LPIPS = {result['avg_lpips']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sgrs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
